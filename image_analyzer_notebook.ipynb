{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b99361",
   "metadata": {},
   "source": [
    "# Image Analysis Notebook\n",
    "\n",
    "This notebook performs a series of analyses on a dataset of categorized images.\n",
    "\n",
    "## Analyses performed:\n",
    "1.  **File Metadata:** Image dimensions, aspect ratio, and file size.\n",
    "2.  **Low-Level Features:** Brightness, contrast, and sharpness.\n",
    "3.  **Texture:** Homogeneity, energy, and correlation from GLCM.\n",
    "4.  **Color:** Average color histograms and dominant color analysis.\n",
    "5.  **SIFT Features:** Bag of Visual Words from SIFT descriptors.\n",
    "6.  **Classification:** XGBoost model trained on all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2363b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e3d942",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Set the data and output directories here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1915ec",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "data_dir = './tp1/data/1/dataset-resized'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519bd62c",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bbb57d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_image_paths(data_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"Gathers image paths and their categories from the data directory.\"\"\"\n",
    "    records = []\n",
    "    for category_dir in Path(data_dir).iterdir():\n",
    "        if not category_dir.is_dir():\n",
    "            continue\n",
    "        category = category_dir.name\n",
    "        for image_path in category_dir.iterdir():\n",
    "            if image_path.suffix.lower() in ['.png', '.jpg', '.jpeg']:\n",
    "                records.append({'path': str(image_path), 'category': category})\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def plot_distribution(df: pd.DataFrame, column: str, title: str):\n",
    "    \"\"\"Plots the distribution of a given column, grouped by category.\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(data=df, x='category', y=column)\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46afc340",
   "metadata": {},
   "source": [
    "## Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e00c39",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def analyze_file_metadata(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Analyzes image dimensions and file sizes.\"\"\"\n",
    "    print(\"Analyzing file metadata (dimensions, file size)...\")\n",
    "    metadata = []\n",
    "    for path in df['path']:\n",
    "        p = Path(path)\n",
    "        try:\n",
    "            file_size = p.stat().st_size\n",
    "            img = cv2.imread(str(p))\n",
    "            if img is not None:\n",
    "                height, width, _ = img.shape\n",
    "                aspect_ratio = width / height\n",
    "                metadata.append({\n",
    "                    'width': width, 'height': height, 'aspect_ratio': aspect_ratio,\n",
    "                    'file_size_kb': file_size / 1024\n",
    "                })\n",
    "            else:\n",
    "                metadata.append({'width': None, 'height': None, 'aspect_ratio': None, 'file_size_kb': None})\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read metadata for {p}: {e}\")\n",
    "            metadata.append({'width': None, 'height': None, 'aspect_ratio': None, 'file_size_kb': None})\n",
    "            \n",
    "    return df.join(pd.DataFrame(metadata, index=df.index)).dropna()\n",
    "\n",
    "\n",
    "def analyze_low_level_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Analyzes brightness, contrast, and sharpness.\"\"\"\n",
    "    print(\"Analyzing low-level features (brightness, contrast, sharpness)...\")\n",
    "    features = []\n",
    "    for path in df['path']:\n",
    "        try:\n",
    "            img = cv2.imread(path)\n",
    "            if img is not None:\n",
    "                gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                brightness = gray_img.mean()\n",
    "                contrast = gray_img.std()\n",
    "                sharpness = cv2.Laplacian(gray_img, cv2.CV_64F).var()\n",
    "                features.append({'brightness': brightness, 'contrast': contrast, 'sharpness': sharpness})\n",
    "            else:\n",
    "                features.append({'brightness': None, 'contrast': None, 'sharpness': None})\n",
    "        except Exception as e:\n",
    "            print(f\"Could not analyze low-level features for {path}: {e}\")\n",
    "            features.append({'brightness': None, 'contrast': None, 'sharpness': None})\n",
    "            \n",
    "    return df.join(pd.DataFrame(features, index=df.index)).dropna()\n",
    "\n",
    "\n",
    "def analyze_texture(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Analyzes texture features using GLCM.\"\"\"\n",
    "    print(\"Analyzing texture features...\")\n",
    "    texture_features = []\n",
    "    for path in df['path']:\n",
    "        try:\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                glcm = graycomatrix(img, distances=[5], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "                homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "                energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "                correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "                texture_features.append({'homogeneity': homogeneity, 'energy': energy, 'correlation': correlation})\n",
    "            else:\n",
    "                texture_features.append({'homogeneity': None, 'energy': None, 'correlation': None})\n",
    "        except Exception as e:\n",
    "            print(f\"Could not analyze texture for {path}: {e}\")\n",
    "            texture_features.append({'homogeneity': None, 'energy': None, 'correlation': None})\n",
    "            \n",
    "    return df.join(pd.DataFrame(texture_features, index=df.index)).dropna()\n",
    "\n",
    "\n",
    "def analyze_dominant_colors(df: pd.DataFrame, n_colors: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"Finds the N dominant colors in each image using KMeans clustering.\"\"\"\n",
    "    print(f\"Analyzing dominant colors (top {n_colors})...\")\n",
    "    \n",
    "    dominant_colors_data = []\n",
    "    \n",
    "    for path in df['path']:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            colors = {}\n",
    "            for i in range(n_colors):\n",
    "                colors[f'dom_color_{i+1}_r'] = None\n",
    "                colors[f'dom_color_{i+1}_g'] = None\n",
    "                colors[f'dom_color_{i+1}_b'] = None\n",
    "            dominant_colors_data.append(colors)\n",
    "            continue\n",
    "            \n",
    "        # Convert to RGB and reshape for KMeans\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        pixels = np.float32(img_rgb.reshape((-1, 3)))\n",
    "        \n",
    "        try:\n",
    "            # Using KMeans to find dominant colors\n",
    "            kmeans = MiniBatchKMeans(n_clusters=n_colors, random_state=42, n_init='auto')\n",
    "            kmeans.fit(pixels)\n",
    "            \n",
    "            # Get the colors and sort them by prevalence\n",
    "            rgb_colors = kmeans.cluster_centers_.astype(int)\n",
    "            _, counts = np.unique(kmeans.labels_, return_counts=True)\n",
    "            sorted_indices = np.argsort(-counts)\n",
    "            sorted_rgb_colors = rgb_colors[sorted_indices]\n",
    "            \n",
    "            # Store as a dictionary, flattened\n",
    "            colors = {}\n",
    "            for i in range(n_colors):\n",
    "                colors[f'dom_color_{i+1}_r'] = sorted_rgb_colors[i][0]\n",
    "                colors[f'dom_color_{i+1}_g'] = sorted_rgb_colors[i][1]\n",
    "                colors[f'dom_color_{i+1}_b'] = sorted_rgb_colors[i][2]\n",
    "            dominant_colors_data.append(colors)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not analyze dominant colors for {path}: {e}\")\n",
    "            colors = {}\n",
    "            for i in range(n_colors):\n",
    "                colors[f'dom_color_{i+1}_r'] = None\n",
    "                colors[f'dom_color_{i+1}_g'] = None\n",
    "                colors[f'dom_color_{i+1}_b'] = None\n",
    "            dominant_colors_data.append(colors)\n",
    "            \n",
    "    return df.join(pd.DataFrame(dominant_colors_data, index=df.index))\n",
    "\n",
    "\n",
    "def analyze_sift_features(df: pd.DataFrame, vocabulary_size: int = 100) -> pd.DataFrame:\n",
    "    \"\"\"Extracts SIFT features using a bag of visual words model.\"\"\"\n",
    "    print(f\"Analyzing SIFT features with vocabulary size {vocabulary_size}...\")\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    # 1. Extract descriptors from all images to build vocabulary\n",
    "    all_descriptors = []\n",
    "    \n",
    "    print(\"Extracting SIFT descriptors for vocabulary...\")\n",
    "    for path in df['path']:\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            _, descriptors = sift.detectAndCompute(img, None)\n",
    "            if descriptors is not None:\n",
    "                all_descriptors.append(descriptors)\n",
    "\n",
    "    if not all_descriptors:\n",
    "        print(\"No SIFT descriptors found to build vocabulary.\")\n",
    "        sift_cols = [f'sift_{i}' for i in range(vocabulary_size)]\n",
    "        return pd.DataFrame(np.nan, index=df.index, columns=sift_cols)\n",
    "\n",
    "    all_descriptors_np = np.vstack(all_descriptors)\n",
    "    \n",
    "    # 2. Build vocabulary using KMeans\n",
    "    print(f\"Building vocabulary with {len(all_descriptors_np)} descriptors...\")\n",
    "    kmeans = MiniBatchKMeans(n_clusters=vocabulary_size, random_state=42, batch_size=256*4, n_init='auto')\n",
    "    kmeans.fit(all_descriptors_np)\n",
    "    \n",
    "    # 3. Create histograms for each image\n",
    "    print(\"Creating feature histograms for each image...\")\n",
    "    histograms = []\n",
    "    for path in df['path']:\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        hist = np.zeros(vocabulary_size)\n",
    "        if img is not None:\n",
    "            _, descriptors = sift.detectAndCompute(img, None)\n",
    "            if descriptors is not None:\n",
    "                words = kmeans.predict(descriptors)\n",
    "                for word in words:\n",
    "                    hist[word] += 1\n",
    "        if np.sum(hist) > 0:\n",
    "            hist = hist / np.sum(hist)\n",
    "        histograms.append(hist)\n",
    "        \n",
    "    sift_features_df = pd.DataFrame(histograms, index=df.index).add_prefix('sift_')\n",
    "    return sift_features_df\n",
    "\n",
    "\n",
    "def plot_average_color_histogram(df: pd.DataFrame):\n",
    "    \"\"\"Calculates and plots the average color histogram for each category.\"\"\"\n",
    "    print(\"Plotting average color histograms...\")\n",
    "    categories = df['category'].unique()\n",
    "    colors = ('b', 'g', 'r')\n",
    "\n",
    "    for category in categories:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        avg_hist = np.zeros((256, len(colors)))\n",
    "        \n",
    "        category_paths = df[df['category'] == category]['path']\n",
    "        image_count = 0\n",
    "        for path in category_paths:\n",
    "            img = cv2.imread(path)\n",
    "            if img is not None:\n",
    "                for i, color in enumerate(colors):\n",
    "                    hist = cv2.calcHist([img], [i], None, [256], [0, 256])\n",
    "                    avg_hist[:, i] += hist.flatten()\n",
    "                image_count += 1\n",
    "        \n",
    "        if image_count > 0:\n",
    "            avg_hist /= image_count\n",
    "            \n",
    "        for i, color in enumerate(colors):\n",
    "            plt.plot(avg_hist[:, i], color=color, label=f'{color.upper()} channel')\n",
    "        \n",
    "        plt.title(f'Average Color Histogram for Category: {category}')\n",
    "        plt.xlabel('Pixel Intensity')\n",
    "        plt.ylabel('Normalized Frequency')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b53d49",
   "metadata": {},
   "source": [
    "## Run Analysis\n",
    "\n",
    "### 1. Get Image Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44cb847",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_image_paths(data_dir)\n",
    "if df.empty:\n",
    "    print(f\"No images found in {data_dir}. Exiting.\")\n",
    "else:\n",
    "    print(f\"Found {len(df)} images in {len(df['category'].unique())} categories.\")\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e0e499",
   "metadata": {},
   "source": [
    "### 2. Analyze and Plot Basic Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56caae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    df_meta = analyze_file_metadata(df.copy())\n",
    "    plot_distribution(df_meta, 'width', 'Image Width Distribution')\n",
    "    plot_distribution(df_meta, 'height', 'Image Height Distribution')\n",
    "    plot_distribution(df_meta, 'aspect_ratio', 'Aspect Ratio Distribution')\n",
    "    plot_distribution(df_meta, 'file_size_kb', 'File Size (KB) Distribution')\n",
    "    display(df_meta.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c38310",
   "metadata": {},
   "source": [
    "### 3. Analyze and Plot Low-Level Visual Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f9d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    df_low_level = analyze_low_level_features(df.copy())\n",
    "    plot_distribution(df_low_level, 'brightness', 'Brightness Distribution')\n",
    "    plot_distribution(df_low_level, 'contrast', 'Contrast Distribution')\n",
    "    plot_distribution(df_low_level, 'sharpness', 'Sharpness (Laplacian Variance) Distribution')\n",
    "    display(df_low_level.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad483dd8",
   "metadata": {},
   "source": [
    "### 4. Analyze and Plot Texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b237084",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    df_texture = analyze_texture(df.copy())\n",
    "    plot_distribution(df_texture, 'homogeneity', 'Texture Homogeneity Distribution')\n",
    "    plot_distribution(df_texture, 'energy', 'Texture Energy Distribution')\n",
    "    plot_distribution(df_texture, 'correlation', 'Texture Correlation Distribution')\n",
    "    display(df_texture.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9cc9fe",
   "metadata": {},
   "source": [
    "### 5. Analyze Dominant Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5db2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    df_dominant_colors = analyze_dominant_colors(df.copy(), n_colors=3)\n",
    "    display(df_dominant_colors.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940411ad",
   "metadata": {},
   "source": [
    "### 6. Plot Color Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e11dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    plot_average_color_histogram(df)\n",
    "    print(\"\\nPlotting complete. Plots are displayed inline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df05466a",
   "metadata": {},
   "source": [
    "## 7. Model Training with XGBoost\n",
    "\n",
    "This section combines all the previously defined features (metadata, low-level, texture, and SIFT) to train a classifier. The feature extraction steps are chained together to ensure that we only train on images for which all features could be successfully extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cee4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    print(\"--- Preparing data for model training ---\")\n",
    "    \n",
    "    # 1. Chain all feature extraction steps to get a consolidated DataFrame.\n",
    "    features_df = analyze_file_metadata(df.copy())\n",
    "    features_df = analyze_low_level_features(features_df)\n",
    "    features_df = analyze_texture(features_df)\n",
    "    features_df = analyze_dominant_colors(features_df, n_colors=3)\n",
    "    \n",
    "    # 2. Extract SIFT features\n",
    "    sift_features = analyze_sift_features(features_df)\n",
    "    \n",
    "    # 3. Combine all features\n",
    "    all_features_df = features_df.join(sift_features)\n",
    "    \n",
    "    # Drop rows with any NaNs that might have been produced\n",
    "    all_features_df.dropna(inplace=True)\n",
    "    \n",
    "    print(f\"\\nTraining on {len(all_features_df)} images with {len(all_features_df.columns) - 2} features.\")\n",
    "    display(all_features_df.head())\n",
    "    \n",
    "    # 4. Prepare data for XGBoost\n",
    "    y = all_features_df['category']\n",
    "    X = all_features_df.drop(columns=['path', 'category'])\n",
    "\n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded)\n",
    "    \n",
    "    # 5. Train XGBoost model\n",
    "    print(\"\\nTraining XGBoost model...\")\n",
    "    model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(le.classes_), use_label_encoder=False, eval_metric='mlogloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 6. Evaluate model\n",
    "    print(\"\\nEvaluating model...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "    \n",
    "    # 7. Plot confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
